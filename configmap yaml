
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-{{ .Values.configMap.nameSuffix }}
  namespace: {{ .Release.Namespace }}
  labels:
    {{ include "Epay_Operations_Service.labels" . | nindent 4 }}
{{ if $.Values.configMap.additionalLabels }}
    {{ toYaml $.Values.configMap.additionalLabels | nindent 4 }}
{{ end }}
{{ if $.Values.configMap.annotations }}
  annotations:
    {{ toYaml $.Values.configMap.annotations | nindent 4 }}
{{ end }}
data:
  application.yml: |
    server:
      servlet:
        context-path: /api/rns/v1
      port: 9097
    security:
      jwt:
        secret:
          issuer: sbi.epay
          key: bsrfgskjfhsdjkhkflkdlksdlfkskfwperip3ke3le3lmldrnkfnhiewjfejfokepfkldkfoikfokork3dklwedlsvflvkfkvlkdfvodkvcdokro3
      whitelist.urls: /webjars/, /actuator/health, /swagger-resources/, /v3/api-docs, /v3/api-docs/**, /swagger-ui/**, /index.html, /login
      cors:
        allowed:
          origins: "*"
        origin: https://dev.epay.sbi
    spring:
      profiles:
        active: DEV
      application:
        name: Recon Settlement Service
      # Db connectivity
      jpa:
        properties:
          hibernate:
            jdbc:
              batch_size: 1000
              order_updates: true
              order_inserts: true
              batch_versioned_data: true
              generate_statistics: true
            show-sql: true
            format_sql: true
        show-sql: true
      datasource:
        driver-class-name: oracle.jdbc.OracleDriver
        url: jdbc:oracle:thin:@10.177.134.124:1590:epaydbdev1
        # username: ${DB_USERNAME}
        # password: ${DB_PASSWORD}
        username: PAYAGGOPERATION
        password: SIA#2025
    
      # Liquibase Properties
      liquibase:
        change-log: classpath:db/changelog/db.changelog-master.xml
        enabled: true
        drop-first: false
      kafka:
        bootstrapServers: dev-cluster-kafka-bootstrap.dev-kafka.svc.cluster.local:9092
            #Kafka consumer config
        consumer:
          groupId: operation-consumers
          keyDeserializer: org.apache.kafka.common.serialization.StringDeserializer
          valueDeserializer: org.apache.kafka.common.serialization.StringDeserializer
          autoOffsetReset: latest
          autoCommitInterval: 100
          enableAutoCommit: true
          sessionTimeoutMS: 300000
          requestTimeoutMS: 420000
          fetchMaxWaitMS: 200
          maxPollRecords: 5
          retryMaxAttempts: 3
          retryBackOffInitialIntervalMS: 10000
          retryBackOffMaxIntervalMS: 30000
          retryBackOffMultiplier: 2
          spring.json.trusted.packages: com.epay.operations
          numberOfConsumers: 10
        #Kafka producer config
        producer:
          acks: all
          retries: 3
          batchSize: 1000
          lingerMs: 1
          bufferMemory: 33554432
          keyDeserializer: org.apache.kafka.common.serialization.StringSerializer
          valueDeserializer: org.apache.kafka.common.serialization.StringSerializer
        #Kafka topic config
        topic:
          recon:
            file: ops_recon_file_topic
            record:
              match: ops_recon_record_matched_topic
              unmatched: ops_recon_record_unmatched_topic
              duplicate: ops_recon_record_duplicate_topic
              fail: ops_recon_fail_ack_topic
          payout: ops_payout_topic
          refund:
            adjust: ops_refund_adjust_detail_topic
            adjust.confirmation: ops_refund_adjust_confirmation_topic
          report:
            generation: ops_report_generation_topic
            confirmation: ops_report_confirmation_topic
          partitions: 4
          replicationFactor: 1
      servlet:
        multipart:
          max-file-size: 50MB
          max-request-size: 50MB
    #spark:
    # app:
        #name: ${spring.application.name}
      #master: local[*]
      #spark://api.dev.sbiepay.sbi:6443
      #spark.master can be:
      #  local[*] for local mode
      #  spark://host:port for Spark Standalone cluster

    logging:
      level:
        liquibase: DEBUG
        org.apache.kafka: ERROR
        com.epay: INFO
        io.kubernetes: DEBUG

    external:
      api:
        services:
          base:
            path:
              admin: http://admin-adminservice.dev-admin.svc.cluster.local:9094/api/admin/v1

    aws:
      s3:
        url: https://s3store.bank.sbi/
        region: ap-south-1
        key: IDHJO1513FFMMNLPR9BC
        secret: avXqEPv5B_QqqPK0D1VJzP3pSyAA4x31Zu_KucQ9
        bucket: epay-nonprod-s3bucket

    #SFTP config
    sftp:
      host: localhost #localhost preprod.sfg.sbi
      port: 2222 #2222 2201
      username: root #root EPAY_CET_2501
      password: root #root Statebank@345
      dir: /home/default/OPS
      session:
        timeout: 30000
        cacheSize: 1
    
    secret:
      key: encryptionKeyForFile134424
      salt: salt_54321
    
    scheduler:
      lockAtLeastFor: PT30S
      lockAtMostFor: PT10M
      cron:
        expression:
          sftp.recon.file: 0/30 * * * * *
          payout.generation.check: 0/30 * * * * *
          transaction.data.sync: 0/30 * * * * *
          payout.report: 0/30 * * * * *
          operation.data.purge: 0/30 * * * * *
          spark.job: 0 0/30 * * * *
          
    
    process:
      generation:
        batch:
          size: 1000
    payout:
      generation:
        time:
          interval: 600000
    
    recon:
      process:
        runner:
          mode: JAVA
    
    flush:
      event:
        logs:
          maxBatchSize: 5000

    jdbc:
      insert:
        batchSize: 5000

    queue:
      batch:
        size:
          event: 5000
    
    #purgin retention day
    purge:
      retentionDays: 7

    k8s:
      auth.enable: false
      path:
        crt: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        token: /var/run/secrets/kubernetes.io/serviceaccount/token
      masterUrl: https://kubernetes.default.svc
      #Spark
    spark:
      app:
        name: ${spring.application.name}
      master: local[*]
      #spark://api.dev.sbiepay.sbi:6443
      #spark.master can be:
      #  local[*] for local mode
      #  spark://host:port for Spark Standalone cluster
      group: "spark.apache.org"
      version: "v1beta1"
      type: "Java"
      mode: "ClusterMode"
      image: "registry.dev.sbiepay.sbi:8443/spark/sparkrecon:4.0.0_12092025v36"
      mainClass: "com.epay.operations.recon.ReconSparkAppMain"
      mainApplicationFile: "local:///opt/spark/work-dir/recon-spark-job.jar"
      arguments: []
      serviceAccount: "spark-sa"
      driverCores: "1"
      driverMemory: "512m"
      executorCores: "1"
      executorInstances: "2"
      executorMemory: "1g"
      nameSpace: "dev-rns"

      labels:
        app: "recon-spark-main"
        component: "recon"
        version: "0.0.1"
        java-version: "21"

      sparkVersion: "4.0.0"

      sparkConf:
        spark.kubernetes.container.image: "registry.dev.sbiepay.sbi:8443/spark/sparkrecon:4.0.0_12092025v36"
        spark.kubernetes.container.image.pullPolicy: "Always"
        spark.driver.memory: "2g"
        spark.driver.cores: "1"
        spark.executor.memory: "512m"
        spark.executor.cores: "1"
        spark.executor.instances: "2"
        spark.kubernetes.authenticate.driver.serviceAccountName: "spark-sa"
        spark.kubernetes.executor.serviceAccount: "spark-sa"
        spark.kubernetes.namespace: "dev-rns"
        spark.kubernetes.driver.label.app: "recon-spark-main"
        spark.kubernetes.executor.label.app: "recon-spark-main"
        spark.kubernetes.driver.label.test: "validation"
        #spark.kubernetes.driver.service.type: ClusterIP
        spark.kubernetes.driver.service.type: LoadBalancer
        spark.kubernetes.executor.label.test: "validation"
        spark.eventLog.enabled: "false"
        spark.sql.adaptive.enabled: "true"
        spark.sql.adaptive.coalescePartitions.enabled: "true"
        spark.driver.extraJavaOptions: ""  
