WARNING: Using incubator modules: jdk.incubator.vector
Files local:///opt/spark/work-dir/recon-spark-job.jar from /opt/spark/work-dir/recon-spark-job.jar to /opt/spark/recon-spark-job.jar
25/10/23 10:09:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/10/23 10:09:15 INFO SparkContext: Running Spark version 4.0.0
25/10/23 10:09:15 INFO SparkContext: OS info Linux, 5.14.0-427.44.1.el9_4.x86_64, amd64
25/10/23 10:09:15 INFO SparkContext: Java version 21.0.7
25/10/23 10:09:15 INFO ResourceUtils: ==============================================================
25/10/23 10:09:15 INFO ResourceUtils: No custom resources configured for spark.driver.
25/10/23 10:09:15 INFO ResourceUtils: ==============================================================
25/10/23 10:09:15 INFO SparkContext: Submitted application: operations-recon-spark-service
25/10/23 10:09:15 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 512, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/10/23 10:09:15 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
25/10/23 10:09:15 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/10/23 10:09:15 INFO SecurityManager: Changing view acls to: spark
25/10/23 10:09:15 INFO SecurityManager: Changing modify acls to: spark
25/10/23 10:09:15 INFO SecurityManager: Changing view acls groups to: spark
25/10/23 10:09:15 INFO SecurityManager: Changing modify acls groups to: spark
25/10/23 10:09:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/23 10:09:15 INFO Utils: Successfully started service 'sparkDriver' on port 7078.
25/10/23 10:09:15 INFO SparkEnv: Registering MapOutputTracker
25/10/23 10:09:15 INFO SparkEnv: Registering BlockManagerMaster
25/10/23 10:09:15 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/10/23 10:09:15 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/10/23 10:09:15 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/10/23 10:09:15 INFO DiskBlockManager: Created local directory at /var/data/spark-4a68493d-c779-413a-a707-5b82fcb412fc/blockmgr-eebc3e30-b202-4918-bb34-920586277739
25/10/23 10:09:15 INFO SparkEnv: Registering OutputCommitCoordinator
25/10/23 10:09:15 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/10/23 10:09:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/10/23 10:09:16 INFO SparkContext: Added JAR local:/opt/spark/work-dir/recon-spark-job.jar at file:/opt/spark/work-dir/recon-spark-job.jar with timestamp 1761214155066
25/10/23 10:09:16 INFO SecurityManager: Changing view acls to: spark
25/10/23 10:09:16 INFO SecurityManager: Changing modify acls to: spark
25/10/23 10:09:16 INFO SecurityManager: Changing view acls groups to: spark
25/10/23 10:09:16 INFO SecurityManager: Changing modify acls groups to: spark
25/10/23 10:09:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY; RPC SSL disabled
25/10/23 10:09:16 INFO SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file
25/10/23 10:09:17 INFO ExecutorPodsAllocator: Going to request 2 executors from Kubernetes for ResourceProfile Id: 0, target: 2, known: 0, sharedSlotFromPendingPods: 2147483647.
25/10/23 10:09:17 INFO ExecutorPodsAllocator: Found 0 reusable PVCs from 0 PVCs
25/10/23 10:09:17 INFO KubernetesClientUtils: Spark configuration files loaded from Some(/opt/spark/conf) : spark.kubernetes.namespace
25/10/23 10:09:18 INFO KubernetesClientUtils: Spark configuration files loaded from Some(/opt/spark/conf) : spark.kubernetes.namespace
25/10/23 10:09:18 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
25/10/23 10:09:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7079.
25/10/23 10:09:18 INFO NettyBlockTransferService: Server created on recon-bboqhxz9cr-0-driver-svc.dev-rns.svc 172.16.17.60:7079
25/10/23 10:09:18 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/10/23 10:09:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, recon-bboqhxz9cr-0-driver-svc.dev-rns.svc, 7079, None)
25/10/23 10:09:18 INFO BlockManagerMasterEndpoint: Registering block manager recon-bboqhxz9cr-0-driver-svc.dev-rns.svc:7079 with 1048.8 MiB RAM, BlockManagerId(driver, recon-bboqhxz9cr-0-driver-svc.dev-rns.svc, 7079, None)
25/10/23 10:09:18 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, recon-bboqhxz9cr-0-driver-svc.dev-rns.svc, 7079, None)
25/10/23 10:09:18 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, recon-bboqhxz9cr-0-driver-svc.dev-rns.svc, 7079, None)
25/10/23 10:09:18 INFO KubernetesClientUtils: Spark configuration files loaded from Some(/opt/spark/conf) : spark.kubernetes.namespace
25/10/23 10:09:18 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
25/10/23 10:09:22 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.16.17.61:56020) with ID 1, ResourceProfileId 0
25/10/23 10:09:22 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.17.61:42207 with 117.0 MiB RAM, BlockManagerId(1, 172.16.17.61, 42207, None)
25/10/23 10:09:22 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.16.17.62:54196) with ID 2, ResourceProfileId 0
25/10/23 10:09:22 INFO KubernetesClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
25/10/23 10:09:23 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.17.62:33921 with 117.0 MiB RAM, BlockManagerId(2, 172.16.17.62, 33921, None)
25/10/23 10:09:24 INFO ReconConfig$$SpringCGLIB$$0: s3EndPoint: https://s3store.bank.sbi/
25/10/23 10:09:24 INFO ReconConfig$$SpringCGLIB$$0: region: ap-south-1
25/10/23 10:09:24 INFO ReconConfig$$SpringCGLIB$$0: bucket: epay-nonprod-s3bucket
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
25/10/23 10:09:26 INFO ReconSparkAppMain: Input properties: {spark.submit.pyFiles=, java.specification.version=21, sun.jnu.encoding=UTF-8, sun.arch.data.model=64, java.vendor.url=https://adoptium.net/, spark.kubernetes.submitInDriver=true, spark.kubernetes.authenticate.driver.serviceAccountName=spark-sa, sun.boot.library.path=/opt/java/openjdk/lib, sun.java.command=org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.driver.bindAddress=172.16.17.60 --conf spark.executorEnv.SPARK_DRIVER_POD_IP=172.16.17.60 --properties-file /opt/spark/conf/spark.properties --class com.epay.operations.recon.ReconSparkAppMain local:///opt/spark/work-dir/recon-spark-job.jar, spark.kubernetes.driver.service.type=LoadBalancer, jdk.debug=release, spark.kubernetes.executor.serviceAccount=spark-sa, io.netty.tryReflectionSetAccessible=true, java.specification.vendor=Oracle Corporation, spark.app.name=com.epay.operations.recon.ReconSparkAppMain, spark.executorEnv.SPARK_DRIVER_POD_IP=172.16.17.60, java.version.date=2025-04-15, java.home=/opt/java/openjdk, spark.kubernetes.executor.label.test=validation, spark.driver.blockManager.port=7079, file.separator=/, java.vm.compressedOopsMode=32-bit, line.separator=
, java.vm.specification.vendor=Oracle Corporation, java.specification.name=Java Platform API Specification, spark.kubernetes.memoryOverheadFactor=0.1, spark.kubernetes.driver.label.spark.operator/name=spark-kubernetes-operator, spark.kubernetes.driver.label.app=recon-spark-main, spark.jars=local:/opt/spark/work-dir/recon-spark-job.jar, spark.driver.port=7078, spark.kubernetes.driver.label.spark.operator/spark-app-name=recon-bboqhxz9cr, sun.management.compiler=HotSpot 64-Bit Tiered Compilers, java.runtime.version=21.0.7+6-LTS, user.name=spark, spark.driver.bindAddress=172.16.17.60, file.encoding=UTF-8, spark.kubernetes.driver.pod.name=recon-bboqhxz9cr-0-driver, rfId=1a6cf13c-df22-4845-a15a-f740e2716016, java.vendor.version=Temurin-21.0.7+6, spark.executor.instances=2, spark.executor.memory=512m, java.io.tmpdir=/tmp, java.version=21.0.7, java.vm.specification.name=Java Virtual Machine Specification, spark.submit.deployMode=client, native.encoding=UTF-8, java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib, spark.kubernetes.container.image=registry.dev.sbiepay.sbi:8443/spark/sparkrecon:4.0.0_12092025t36, stderr.encoding=UTF-8, java.vendor=Eclipse Adoptium, sun.io.unicode.encoding=UnicodeLittle, spark.kubernetes.driver.label.test=validation, java.class.path=hive-jackson/*:/opt/spark/conf/:/opt/spark/jars/slf4j-api-2.0.16.jar:/opt/spark/jars/HikariCP-2.5.1.jar:/opt/spark/jars/JLargeArrays-1.5.jar:/opt/spark/jars/JTransforms-3.1.jar:/opt/spark/jars/RoaringBitmap-1.3.0.jar:/opt/spark/jars/ST4-4.0.4.jar:/opt/spark/jars/aircompressor-2.0.2.jar:/opt/spark/jars/algebra_2.13-2.8.0.jar:/opt/spark/jars/annotations-17.0.0.jar:/opt/spark/jars/antlr-runtime-3.5.2.jar:/opt/spark/jars/antlr4-runtime-4.13.1.jar:/opt/spark/jars/aopalliance-repackaged-3.0.6.jar:/opt/spark/jars/arpack-3.0.3.jar:/opt/spark/jars/arpack_combined_all-0.1.jar:/opt/spark/jars/arrow-format-18.1.0.jar:/opt/spark/jars/arrow-memory-core-18.1.0.jar:/opt/spark/jars/arrow-memory-netty-18.1.0.jar:/opt/spark/jars/arrow-memory-netty-buffer-patch-18.1.0.jar:/opt/spark/jars/arrow-vector-18.1.0.jar:/opt/spark/jars/audience-annotations-0.12.0.jar:/opt/spark/jars/avro-1.12.0.jar:/opt/spark/jars/avro-ipc-1.12.0.jar:/opt/spark/jars/avro-mapred-1.12.0.jar:/opt/spark/jars/bcprov-jdk18on-1.80.jar:/opt/spark/jars/blas-3.0.3.jar:/opt/spark/jars/breeze-macros_2.13-2.1.0.jar:/opt/spark/jars/breeze_2.13-2.1.0.jar:/opt/spark/jars/cats-kernel_2.13-2.8.0.jar:/opt/spark/jars/checker-qual-3.43.0.jar:/opt/spark/jars/chill-java-0.10.0.jar:/opt/spark/jars/chill_2.13-0.10.0.jar:/opt/spark/jars/commons-cli-1.9.0.jar:/opt/spark/jars/commons-codec-1.17.2.jar:/opt/spark/jars/commons-collections-3.2.2.jar:/opt/spark/jars/commons-collections4-4.4.jar:/opt/spark/jars/commons-compiler-3.1.9.jar:/opt/spark/jars/commons-compress-1.27.1.jar:/opt/spark/jars/commons-crypto-1.1.0.jar:/opt/spark/jars/commons-dbcp-1.4.jar:/opt/spark/jars/commons-io-2.18.0.jar:/opt/spark/jars/commons-lang-2.6.jar:/opt/spark/jars/commons-lang3-3.17.0.jar:/opt/spark/jars/commons-math3-3.6.1.jar:/opt/spark/jars/commons-pool-1.5.4.jar:/opt/spark/jars/commons-text-1.13.0.jar:/opt/spark/jars/compress-lzf-1.1.2.jar:/opt/spark/jars/curator-client-5.7.1.jar:/opt/spark/jars/curator-framework-5.7.1.jar:/opt/spark/jars/curator-recipes-5.7.1.jar:/opt/spark/jars/datanucleus-api-jdo-4.2.4.jar:/opt/spark/jars/datanucleus-core-4.1.17.jar:/opt/spark/jars/datanucleus-rdbms-4.1.19.jar:/opt/spark/jars/datasketches-java-6.1.1.jar:/opt/spark/jars/datasketches-memory-3.0.2.jar:/opt/spark/jars/derby-10.16.1.1.jar:/opt/spark/jars/derbyshared-10.16.1.1.jar:/opt/spark/jars/derbytools-10.16.1.1.jar:/opt/spark/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/spark/jars/error_prone_annotations-2.36.0.jar:/opt/spark/jars/failureaccess-1.0.2.jar:/opt/spark/jars/flatbuffers-java-24.3.25.jar:/opt/spark/jars/gson-2.11.0.jar:/opt/spark/jars/guava-33.4.0-jre.jar:/opt/spark/jars/hadoop-client-api-3.4.1.jar:/opt/spark/jars/hadoop-client-runtime-3.4.1.jar:/opt/spark/jars/hive-beeline-2.3.10.jar:/opt/spark/jars/hive-cli-2.3.10.jar:/opt/spark/jars/hive-common-2.3.10.jar:/opt/spark/jars/hive-exec-2.3.10-core.jar:/opt/spark/jars/hive-jdbc-2.3.10.jar:/opt/spark/jars/hive-metastore-2.3.10.jar:/opt/spark/jars/hive-serde-2.3.10.jar:/opt/spark/jars/hive-service-rpc-4.0.0.jar:/opt/spark/jars/hive-shims-0.23-2.3.10.jar:/opt/spark/jars/hive-shims-2.3.10.jar:/opt/spark/jars/hive-shims-common-2.3.10.jar:/opt/spark/jars/hive-shims-scheduler-2.3.10.jar:/opt/spark/jars/hive-storage-api-2.8.1.jar:/opt/spark/jars/hk2-api-3.0.6.jar:/opt/spark/jars/hk2-locator-3.0.6.jar:/opt/spark/jars/hk2-utils-3.0.6.jar:/opt/spark/jars/httpclient-4.5.14.jar:/opt/spark/jars/httpcore-4.4.16.jar:/opt/spark/jars/icu4j-76.1.jar:/opt/spark/jars/istack-commons-runtime-4.1.2.jar:/opt/spark/jars/ivy-2.5.3.jar:/opt/spark/jars/j2objc-annotations-3.0.0.jar:/opt/spark/jars/jackson-annotations-2.18.2.jar:/opt/spark/jars/jackson-core-2.18.2.jar:/opt/spark/jars/jackson-databind-2.18.2.jar:/opt/spark/jars/jackson-dataformat-yaml-2.18.2.jar:/opt/spark/jars/jackson-datatype-jsr310-2.18.2.jar:/opt/spark/jars/jackson-module-scala_2.13-2.18.2.jar:/opt/spark/jars/jakarta.activation-api-2.1.3.jar:/opt/spark/jars/jakarta.annotation-api-2.1.1.jar:/opt/spark/jars/jakarta.inject-api-2.0.1.jar:/opt/spark/jars/jakarta.servlet-api-5.0.0.jar:/opt/spark/jars/jakarta.validation-api-3.0.2.jar:/opt/spark/jars/jakarta.ws.rs-api-3.0.0.jar:/opt/spark/jars/jpam-1.1.jar:/opt/spark/jars/jakarta.xml.bind-api-4.0.2.jar:/opt/spark/jars/janino-3.1.9.jar:/opt/spark/jars/java-diff-utils-4.15.jar:/opt/spark/jars/javassist-3.30.2-GA.jar:/opt/spark/jars/javax.jdo-3.2.0-m3.jar:/opt/spark/jars/javax.servlet-api-4.0.1.jar:/opt/spark/jars/javolution-5.5.1.jar:/opt/spark/jars/jaxb-core-4.0.5.jar:/opt/spark/jars/jaxb-runtime-4.0.5.jar:/opt/spark/jars/jcl-over-slf4j-2.0.16.jar:/opt/spark/jars/jdo-api-3.0.1.jar:/opt/spark/jars/jersey-client-3.0.16.jar:/opt/spark/jars/jersey-common-3.0.16.jar:/opt/spark/jars/jersey-container-servlet-3.0.16.jar:/opt/spark/jars/jersey-container-servlet-core-3.0.16.jar:/opt/spark/jars/jersey-hk2-3.0.16.jar:/opt/spark/jars/jersey-server-3.0.16.jar:/opt/spark/jars/jjwt-api-0.12.6.jar:/opt/spark/jars/jjwt-impl-0.12.6.jar:/opt/spark/jars/jjwt-jackson-0.12.6.jar:/opt/spark/jars/jline-2.14.6.jar:/opt/spark/jars/jline-3.27.1-jdk8.jar:/opt/spark/jars/joda-time-2.13.0.jar:/opt/spark/jars/jodd-core-3.5.2.jar:/opt/spark/jars/json-1.8.jar:/opt/spark/jars/json4s-ast_2.13-4.0.7.jar:/opt/spark/jars/json4s-core_2.13-4.0.7.jar:/opt/spark/jars/json4s-jackson-core_2.13-4.0.7.jar:/opt/spark/jars/json4s-jackson_2.13-4.0.7.jar:/opt/spark/jars/json4s-scalap_2.13-4.0.7.jar:/opt/spark/jars/jsr305-3.0.0.jar:/opt/spark/jars/jta-1.1.jar:/opt/spark/jars/jul-to-slf4j-2.0.16.jar:/opt/spark/jars/kryo-shaded-4.0.3.jar:/opt/spark/jars/kubernetes-client-7.1.0.jar:/opt/spark/jars/kubernetes-client-api-7.1.0.jar:/opt/spark/jars/kubernetes-httpclient-vertx-7.1.0.jar:/opt/spark/jars/kubernetes-model-admissionregistration-7.1.0.jar:/opt/spark/jars/kubernetes-model-apiextensions-7.1.0.jar:/opt/spark/jars/kubernetes-model-apps-7.1.0.jar:/opt/spark/jars/kubernetes-model-autoscaling-7.1.0.jar:/opt/spark/jars/kubernetes-model-batch-7.1.0.jar:/opt/spark/jars/kubernetes-model-certificates-7.1.0.jar:/opt/spark/jars/kubernetes-model-common-7.1.0.jar:/opt/spark/jars/kubernetes-model-coordination-7.1.0.jar:/opt/spark/jars/kubernetes-model-core-7.1.0.jar:/opt/spark/jars/kubernetes-model-discovery-7.1.0.jar:/opt/spark/jars/kubernetes-model-events-7.1.0.jar:/opt/spark/jars/kubernetes-model-extensions-7.1.0.jar:/opt/spark/jars/kubernetes-model-flowcontrol-7.1.0.jar:/opt/spark/jars/kubernetes-model-gatewayapi-7.1.0.jar:/opt/spark/jars/kubernetes-model-metrics-7.1.0.jar:/opt/spark/jars/kubernetes-model-networking-7.1.0.jar:/opt/spark/jars/kubernetes-model-node-7.1.0.jar:/opt/spark/jars/kubernetes-model-policy-7.1.0.jar:/opt/spark/jars/kubernetes-model-rbac-7.1.0.jar:/opt/spark/jars/kubernetes-model-resource-7.1.0.jar:/opt/spark/jars/kubernetes-model-scheduling-7.1.0.jar:/opt/spark/jars/kubernetes-model-storageclass-7.1.0.jar:/opt/spark/jars/lapack-3.0.3.jar:/opt/spark/jars/leveldbjni-all-1.8.jar:/opt/spark/jars/libfb303-0.9.3.jar:/opt/spark/jars/libthrift-0.16.0.jar:/opt/spark/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/spark/jars/log4j-1.2-api-2.24.3.jar:/opt/spark/jars/log4j-api-2.24.3.jar:/opt/spark/jars/log4j-core-2.24.3.jar:/opt/spark/jars/log4j-layout-template-json-2.24.3.jar:/opt/spark/jars/log4j-slf4j2-impl-2.24.3.jar:/opt/spark/jars/lz4-java-1.8.0.jar:/opt/spark/jars/metrics-core-4.2.30.jar:/opt/spark/jars/metrics-graphite-4.2.30.jar:/opt/spark/jars/metrics-jmx-4.2.30.jar:/opt/spark/jars/metrics-json-4.2.30.jar:/opt/spark/jars/metrics-jvm-4.2.30.jar:/opt/spark/jars/minlog-1.3.0.jar:/opt/spark/jars/netty-all-4.1.118.Final.jar:/opt/spark/jars/netty-buffer-4.1.118.Final.jar:/opt/spark/jars/netty-codec-4.1.118.Final.jar:/opt/spark/jars/netty-codec-dns-4.1.118.Final.jar:/opt/spark/jars/netty-codec-http-4.1.118.Final.jar:/opt/spark/jars/netty-codec-http2-4.1.118.Final.jar:/opt/spark/jars/netty-codec-socks-4.1.118.Final.jar:/opt/spark/jars/netty-common-4.1.118.Final.jar:/opt/spark/jars/netty-handler-4.1.118.Final.jar:/opt/spark/jars/netty-handler-proxy-4.1.118.Final.jar:/opt/spark/jars/netty-resolver-4.1.118.Final.jar:/opt/spark/jars/netty-resolver-dns-4.1.118.Final.jar:/opt/spark/jars/netty-tcnative-boringssl-static-2.0.70.Final-linux-aarch_64.jar:/opt/spark/jars/netty-tcnative-boringssl-static-2.0.70.Final-linux-x86_64.jar:/opt/spark/jars/netty-tcnative-boringssl-static-2.0.70.Final-osx-aarch_64.jar:/opt/spark/jars/netty-tcnative-boringssl-static-2.0.70.Final-osx-x86_64.jar:/opt/spark/jars/netty-tcnative-boringssl-static-2.0.70.Final-windows-x86_64.jar:/opt/spark/jars/netty-tcnative-classes-2.0.70.Final.jar:/opt/spark/jars/netty-transport-4.1.118.Final.jar:/opt/spark/jars/netty-transport-classes-epoll-4.1.118.Final.jar:/opt/spark/jars/netty-transport-classes-kqueue-4.1.118.Final.jar:/opt/spark/jars/netty-transport-native-epoll-4.1.118.Final-linux-aarch_64.jar:/opt/spark/jars/netty-transport-native-epoll-4.1.118.Final-linux-riscv64.jar:/opt/spark/jars/netty-transport-native-epoll-4.1.118.Final-linux-x86_64.jar:/opt/spark/jars/netty-transport-native-kqueue-4.1.118.Final-osx-aarch_64.jar:/opt/spark/jars/netty-transport-native-kqueue-4.1.118.Final-osx-x86_64.jar:/opt/spark/jars/netty-transport-native-unix-common-4.1.118.Final.jar:/opt/spark/jars/objenesis-3.3.jar:/opt/spark/jars/opencsv-2.3.jar:/opt/spark/jars/orc-core-2.1.2-shaded-protobuf.jar:/opt/spark/jars/orc-format-1.1.0-shaded-protobuf.jar:/opt/spark/jars/orc-mapreduce-2.1.2-shaded-protobuf.jar:/opt/spark/jars/orc-shims-2.1.2.jar:/opt/spark/jars/oro-2.0.8.jar:/opt/spark/jars/osgi-resource-locator-1.0.3.jar:/opt/spark/jars/paranamer-2.8.jar:/opt/spark/jars/parquet-column-1.15.2.jar:/opt/spark/jars/parquet-common-1.15.2.jar:/opt/spark/jars/parquet-encoding-1.15.2.jar:/opt/spark/jars/parquet-format-structures-1.15.2.jar:/opt/spark/jars/parquet-hadoop-1.15.2.jar:/opt/spark/jars/parquet-jackson-1.15.2.jar:/opt/spark/jars/pickle-1.5.jar:/opt/spark/jars/py4j-0.10.9.9.jar:/opt/spark/jars/rocksdbjni-9.8.4.jar:/opt/spark/jars/scala-collection-compat_2.13-2.7.0.jar:/opt/spark/jars/scala-compiler-2.13.16.jar:/opt/spark/jars/scala-library-2.13.16.jar:/opt/spark/jars/scala-parallel-collections_2.13-1.2.0.jar:/opt/spark/jars/scala-parser-combinators_2.13-2.4.0.jar:/opt/spark/jars/scala-reflect-2.13.16.jar:/opt/spark/jars/scala-xml_2.13-2.3.0.jar:/opt/spark/jars/slf4j-api-2.0.16.jar:/opt/spark/jars/snakeyaml-2.3.jar:/opt/spark/jars/snakeyaml-engine-2.9.jar:/opt/spark/jars/snappy-java-1.1.10.7.jar:/opt/spark/jars/spark-catalyst_2.13-4.0.0.jar:/opt/spark/jars/spark-common-utils_2.13-4.0.0.jar:/opt/spark/jars/spark-connect_2.13-4.0.0.jar:/opt/spark/jars/spark-core_2.13-4.0.0.jar:/opt/spark/jars/spark-graphx_2.13-4.0.0.jar:/opt/spark/jars/spark-hive-thriftserver_2.13-4.0.0.jar:/opt/spark/jars/spark-hive_2.13-4.0.0.jar:/opt/spark/jars/spark-kubernetes_2.13-4.0.0.jar:/opt/spark/jars/spark-kvstore_2.13-4.0.0.jar:/opt/spark/jars/spark-launcher_2.13-4.0.0.jar:/opt/spark/jars/spark-mllib-local_2.13-4.0.0.jar:/opt/spark/jars/spark-mllib_2.13-4.0.0.jar:/opt/spark/jars/spark-network-common_2.13-4.0.0.jar:/opt/spark/jars/spark-network-shuffle_2.13-4.0.0.jar:/opt/spark/jars/spark-repl_2.13-4.0.0.jar:/opt/spark/jars/spark-sketch_2.13-4.0.0.jar:/opt/spark/jars/spark-sql-api_2.13-4.0.0.jar:/opt/spark/jars/spark-sql_2.13-4.0.0.jar:/opt/spark/jars/spark-streaming_2.13-4.0.0.jar:/opt/spark/jars/spark-tags_2.13-4.0.0.jar:/opt/spark/jars/spark-unsafe_2.13-4.0.0.jar:/opt/spark/jars/spark-variant_2.13-4.0.0.jar:/opt/spark/jars/spark-yarn_2.13-4.0.0.jar:/opt/spark/jars/spire-macros_2.13-0.18.0.jar:/opt/spark/jars/spire-platform_2.13-0.18.0.jar:/opt/spark/jars/spire-util_2.13-0.18.0.jar:/opt/spark/jars/spire_2.13-0.18.0.jar:/opt/spark/jars/stax-api-1.0.1.jar:/opt/spark/jars/stream-2.9.8.jar:/opt/spark/jars/super-csv-2.2.0.jar:/opt/spark/jars/threeten-extra-1.8.0.jar:/opt/spark/jars/tink-1.16.0.jar:/opt/spark/jars/transaction-api-1.1.jar:/opt/spark/jars/univocity-parsers-2.9.1.jar:/opt/spark/jars/vertx-auth-common-4.5.12.jar:/opt/spark/jars/vertx-core-4.5.12.jar:/opt/spark/jars/vertx-web-client-4.5.12.jar:/opt/spark/jars/vertx-web-common-4.5.12.jar:/opt/spark/jars/xbean-asm9-shaded-4.26.jar:/opt/spark/jars/xmlschema-core-2.3.1.jar:/opt/spark/jars/xz-1.10.jar:/opt/spark/jars/zjsonpatch-7.1.0.jar:/opt/spark/jars/zookeeper-3.9.3.jar:/opt/spark/jars/zookeeper-jute-3.9.3.jar:/opt/spark/jars/zstd-jni-1.5.6-9.jar, java.vm.vendor=Eclipse Adoptium, user.timezone=Etc/UTC, spark.sql.adaptive.enabled=true, os.name=Linux, java.vm.specification.version=21, sun.java.launcher=SUN_STANDARD, user.country=US, spark.driver.memory=2g, spark.master=k8s://https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT, spark.driver.cores=1, SPARK_SUBMIT=true, sun.cpu.endian=little, user.home=/nonexistent, user.language=en, derby.connection.requireAuthentication=false, spark.driver.host=recon-bboqhxz9cr-0-driver-svc.dev-rns.svc, spark.app.id=recon-bboqhxz9cr-0, spark.driver.extraJavaOptions=-DrfId=1a6cf13c-df22-4845-a15a-f740e2716016, spark.kubernetes.driver.service.label.spark.operator/name=spark-kubernetes-operator, spark.kubernetes.driver.service.label.spark.operator/spark-app-name=recon-bboqhxz9cr, spark.kubernetes.executor.label.app=recon-spark-main, spark.kubernetes.container.image.pullPolicy=Always, kubernetes.request.retry.backoffLimit=3, spark.kubernetes.resource.type=java, stdout.encoding=UTF-8, path.separator=:, os.version=5.14.0-427.44.1.el9_4.x86_64, java.runtime.name=OpenJDK Runtime Environment, spark.kubernetes.namespace=dev-rns, spark.app.submitTime=1761214150940, spark.kubernetes.executor.label.spark.operator/spark-app-name=recon-bboqhxz9cr, spark.sql.adaptive.coalescePartitions.enabled=true, java.vm.name=OpenJDK 64-Bit Server VM, java.vendor.url.bug=https://github.com/adoptium/adoptium-support/issues, jetty.git.hash=5dfc59a691b748796f922208956bd1f2794bcd16, user.dir=/opt/spark, spark.repl.local.jars=local:///opt/spark/work-dir/recon-spark-job.jar, os.arch=amd64, spark.executor.cores=1, spark.kubernetes.executor.label.spark.operator/name=spark-kubernetes-operator, java.vm.info=mixed mode, sharing, java.vm.version=21.0.7+6-LTS, spark.eventLog.enabled=false, jdk.reflect.useDirectMethodHandle=false, java.class.version=65.0}
25/10/23 10:09:26 INFO ReconSparkAppMain: Get env properties : null
25/10/23 10:09:26 INFO ReconSparkAppMain: Application Context Created!!!
25/10/23 10:09:26 INFO SparkReconProcessingService: Step-1: Fetch recon file details by rfId : 1a6cf13c-df22-4845-a15a-f740e2716016
25/10/23 10:09:26 INFO SparkReconProcessingService: Fetching recon file data by rfId : 1a6cf13c-df22-4845-a15a-f740e2716016
25/10/23 10:09:26 INFO ReconFileRepository: Getting recon file for rfId: 1a6cf13c-df22-4845-a15a-f740e2716016
25/10/23 10:09:27 INFO SparkReconProcessingService: Step-2: Fetch Bank config.
25/10/23 10:09:27 INFO AdminServiceClient: Fetching bank config from admin service: 
25/10/23 10:09:27 INFO AdminServiceClient: Uri : [http://admin-adminservice.dev-admin.svc.cluster.local:9094/api/admin/v1/rns/3baff772-e6c3-ecfb-e063-7c86b10aa8a6]
25/10/23 10:09:28 INFO SparkReconProcessingService: Step-3: Load recon file data.
25/10/23 10:09:28 INFO ReconFileReaderService: Loading file [TXT] data as dataSet.
25/10/23 10:09:28 INFO ReconFileReaderService: Loading txt file  from s3 : [F:\Epay\epay_operations_service\recon-spark-job\DHANLAXMI-03032025.txt]
25/10/23 10:09:28 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/10/23 10:09:28 INFO SharedState: Warehouse path is 'file:/opt/spark/spark-warehouse'.
25/10/23 10:09:28 INFO ReconFileReaderService: Preparing s3 path : F:\Epay\epay_operations_service\recon-spark-job\DHANLAXMI-03032025.txt
25/10/23 10:09:28 INFO S3Service: Reading file [F:\Epay\epay_operations_service\recon-spark-job\DHANLAXMI-03032025.txt] from S3
25/10/23 10:09:28 INFO S3Service: Get object request : GetObjectRequest(Bucket=epay-nonprod-s3bucket, Key=F:\Epay\epay_operations_service\recon-spark-job\DHANLAXMI-03032025.txt)
25/10/23 10:09:29 ERROR S3Service: Failed to read file[F:\Epay\epay_operations_service\recon-spark-job\DHANLAXMI-03032025.txt] from S3 with error: The specified key does not exist. (Service: S3, Status Code: 404, Request ID: 2642959434)
com.epay.operations.recon.spark.exception.OpsException: The specified key does not exist. (Service: S3, Status Code: 404, Request ID: 2642959434)
	at com.epay.operations.recon.spark.service.S3Service.readFile(S3Service.java:38)
	at com.epay.operations.recon.spark.service.ReconFileReaderService.buildReconFilePath(ReconFileReaderService.java:131)
	at com.epay.operations.recon.spark.service.ReconFileReaderService.loadTxt(ReconFileReaderService.java:78)
	at com.epay.operations.recon.spark.service.ReconFileReaderService.loadReconFileDataset(ReconFileReaderService.java:50)
	at com.epay.operations.recon.spark.service.SparkReconProcessingService.reconProcessing(SparkReconProcessingService.java:65)
	at com.epay.operations.recon.ReconSparkAppMain.main(ReconSparkAppMain.java:69)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1027)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
25/10/23 10:09:29 ERROR ReconSparkAppMain: Exception while the recon process for rfId[1a6cf13c-df22-4845-a15a-f740e2716016], error message: The specified key does not exist. (Service: S3, Status Code: 404, Request ID: 2642959434)
25/10/23 10:09:29 INFO ReconSparkAppMain: Calling callback OPS API: http://ops-operationsservice.dev-spark.svc.cluster.local:9097/api/rns/v1/spark/recon-complete-callback
25/10/23 10:09:29 INFO ReconSparkAppMain: payload: {"rfId":"1a6cf13c-df22-4845-a15a-f740e2716016","jobId":"9f921ded-fcf4-4043-8edb-27608d978d26","status":"FAILED","message":"Failed recon spark job, error message: The specified key does not exist. (Service: S3, Status Code: 404, Request ID: 2642959434)"}
25/10/23 10:09:29 ERROR ReconSparkAppMain: IOException while calling the callback endpoint, error message: HTTP/1.1 header parser received no bytes
25/10/23 10:09:29 INFO SparkContext: SparkContext is stopping with exitCode 0 from stop at SparkSubmit.scala:1036.
25/10/23 10:09:29 INFO SparkUI: Stopped Spark web UI at http://recon-bboqhxz9cr-0-driver-svc.dev-rns.svc:4040
25/10/23 10:09:29 INFO KubernetesClusterSchedulerBackend: Shutting down all executors
25/10/23 10:09:29 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Asking each executor to shut down
25/10/23 10:09:29 INFO ExecutorPodsWatchSnapshotSource: Kubernetes client has been closed.
25/10/23 10:09:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/10/23 10:09:29 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB
25/10/23 10:09:29 INFO MemoryStore: MemoryStore cleared
25/10/23 10:09:29 INFO BlockManager: BlockManager stopped
25/10/23 10:09:29 INFO BlockManagerMaster: BlockManagerMaster stopped
25/10/23 10:09:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/10/23 10:09:29 INFO SparkContext: Successfully stopped SparkContext
25/10/23 10:09:30 INFO ShutdownHookManager: Shutdown hook called
25/10/23 10:09:30 INFO ShutdownHookManager: Deleting directory /var/data/spark-4a68493d-c779-413a-a707-5b82fcb412fc/spark-b3a20ccd-f7e7-4514-af0c-8d65eecfb79e
25/10/23 10:09:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-b9c377b9-aa10-47ef-932a-3c51aa2fcccb
